import os
import json
from pathlib import Path
from typing import Dict, List, Any, Tuple
import fnmatch
from config import Config

class ProjectSerializer:
    """ØªØ¨Ø¯ÛŒÙ„ Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ù‡ ÙØ±Ù…Øª Ù‚Ø§Ø¨Ù„ Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ LLM Ùˆ Ø¨Ø±Ø¹Ú©Ø³"""
    
    def __init__(self, project_path: str):
        self.project_path = Path(project_path).resolve()
        self.last_snapshot = {}  # Ø¨Ø±Ø§ÛŒ Ø±Ø¯ÛŒØ§Ø¨ÛŒ ØªØºÛŒÛŒØ±Ø§Øª
        
    def should_ignore(self, path: Path) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¢ÛŒØ§ ÙØ§ÛŒÙ„ ÛŒØ§ Ù¾ÙˆØ´Ù‡ Ø¨Ø§ÛŒØ¯ Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ø´ÙˆØ¯"""
        path_str = str(path)
        
        for pattern in Config.IGNORE_PATTERNS:
            if fnmatch.fnmatch(path_str, f'*{pattern}*'):
                return True
        
        if path.is_file():
            try:
                if path.stat().st_size > Config.MAX_FILE_SIZE:
                    print(f"âš ï¸  ÙØ§ÛŒÙ„ {path.name} Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ø¨Ø²Ø±Ú¯ Ø§Ø³Øª")
                    return True
            except:
                pass
                
        return False
    
    def is_binary_file(self, file_path: Path) -> bool:
        """Ø¨Ø±Ø±Ø³ÛŒ Ø§ÛŒÙ†Ú©Ù‡ ÙØ§ÛŒÙ„ binary Ø§Ø³Øª ÛŒØ§ text"""
        try:
            with open(file_path, 'tr', encoding='utf-8') as f:
                f.read(1024)
            return False
        except:
            return True
    
    def load_project_files(self) -> List[Dict[str, Any]]:
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾Ø±ÙˆÚ˜Ù‡"""
        if not self.project_path.exists():
            raise FileNotFoundError(f"Ù…Ø³ÛŒØ± Ù¾Ø±ÙˆÚ˜Ù‡ ÛŒØ§ÙØª Ù†Ø´Ø¯: {self.project_path}")
        
        files = []
        ignored_count = 0
        binary_count = 0
        
        for root, dirs, filenames in os.walk(self.project_path):
            root_path = Path(root)
            dirs[:] = [d for d in dirs if not self.should_ignore(root_path / d)]
            
            for filename in filenames:
                file_path = root_path / filename
                
                if self.should_ignore(file_path):
                    ignored_count += 1
                    continue
                
                if self.is_binary_file(file_path):
                    binary_count += 1
                    continue
                
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    relative_path = file_path.relative_to(self.project_path)
                    
                    files.append({
                        "path": str(relative_path).replace('\\', '/'),
                        "content": content
                    })
                    
                except Exception as e:
                    print(f"âš ï¸  Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† {file_path.name}: {e}")
                    continue
        
        print(f"\nğŸ“Š Ø¢Ù…Ø§Ø±:")
        print(f"   âœ… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§: {len(files)}")
        print(f"   â­ï¸  Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡: {ignored_count}")
        print(f"   ğŸ”’ Binary: {binary_count}")
        
        # Ø°Ø®ÛŒØ±Ù‡ snapshot
        self.last_snapshot = {f["path"]: f["content"] for f in files}
        
        return files
    
    def serialize_project(self, selected_files: List[str] = None) -> str:
        """ØªØ¨Ø¯ÛŒÙ„ Ù¾Ø±ÙˆÚ˜Ù‡ Ø¨Ù‡ JSON"""
        files = self.load_project_files()
        
        # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ
        if selected_files:
            files = [f for f in files if f["path"] in selected_files]
        
        project_data = {
            "project_name": self.project_path.name,
            "base_path": str(self.project_path),
            "total_files": len(files),
            "files": files
        }
        
        json_output = json.dumps(project_data, ensure_ascii=False, indent=2)
        return json_output
    
    def serialize_changes_only(self, current_files: List[Dict[str, Any]]) -> str:
        """Ø®Ø±ÙˆØ¬ÛŒ ÙÙ‚Ø· ØªØºÛŒÛŒØ±Ø§Øª (Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØªØ±)"""
        changes = []
        current_paths = {f["path"]: f["content"] for f in current_files}
        
        # ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØªØºÛŒÛŒØ± ÛŒØ§ÙØªÙ‡ ÛŒØ§ Ø¬Ø¯ÛŒØ¯
        for path, content in current_paths.items():
            if path not in self.last_snapshot:
                # ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯
                changes.append({
                    "path": path,
                    "content": content,
                    "action": "added"
                })
            elif self.last_snapshot[path] != content:
                # ÙØ§ÛŒÙ„ ØªØºÛŒÛŒØ± ÛŒØ§ÙØªÙ‡
                changes.append({
                    "path": path,
                    "content": content,
                    "action": "modified"
                })
        
        # ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø­Ø°Ù Ø´Ø¯Ù‡
        for path in self.last_snapshot.keys():
            if path not in current_paths:
                changes.append({
                    "path": path,
                    "action": "deleted"
                })
        
        if not changes:
            # Ù‡ÛŒÚ† ØªØºÛŒÛŒØ±ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯
            return json.dumps({
                "project_name": self.project_path.name,
                "changes_only": True,
                "message": "Ù‡ÛŒÚ† ØªØºÛŒÛŒØ±ÛŒ Ø´Ù†Ø§Ø³Ø§ÛŒÛŒ Ù†Ø´Ø¯",
                "files": []
            }, ensure_ascii=False, indent=2)
        
        project_data = {
            "project_name": self.project_path.name,
            "changes_only": True,
            "total_changes": len(changes),
            "files": changes
        }
        
        return json.dumps(project_data, ensure_ascii=False, indent=2)
    
    def split_into_parts(self, json_str: str, max_chars: int) -> List[str]:
        """ØªÙ‚Ø³ÛŒÙ… JSON Ø¨Ù‡ Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©ØªØ±"""
        if len(json_str) <= max_chars:
            return [json_str]
        
        try:
            data = json.loads(json_str)
        except:
            # Ø§Ú¯Ø± parse Ù†Ø´Ø¯ØŒ ØªÙ‚Ø³ÛŒÙ… Ø³Ø§Ø¯Ù‡
            return self._simple_split(json_str, max_chars)
        
        # ØªÙ‚Ø³ÛŒÙ… Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§
        files = data.get("files", [])
        if not files:
            return [json_str]
        
        parts = []
        header = {
            "project_name": data.get("project_name"),
            "base_path": data.get("base_path"),
            "changes_only": data.get("changes_only", False),
            "total_files": data.get("total_files", len(files))
        }
        
        current_part_files = []
        current_size = len(json.dumps(header, ensure_ascii=False))
        
        for file_obj in files:
            file_json = json.dumps(file_obj, ensure_ascii=False)
            file_size = len(file_json)
            
            # Ø§Ú¯Ø± ÛŒÚ© ÙØ§ÛŒÙ„ Ø®ÛŒÙ„ÛŒ Ø¨Ø²Ø±Ú¯ Ø§Ø³Øª
            if file_size > max_chars:
                # Ø§Ú¯Ø± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯ØŒ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ø°Ø®ÛŒØ±Ù‡ Ú©Ù†
                if current_part_files:
                    part_data = header.copy()
                    part_data["files"] = current_part_files
                    parts.append(json.dumps(part_data, ensure_ascii=False, indent=2))
                    current_part_files = []
                    current_size = len(json.dumps(header, ensure_ascii=False))
                
                # ÙØ§ÛŒÙ„ Ø¨Ø²Ø±Ú¯ Ø±Ø§ Ø¨Ù‡ ØªÙ†Ù‡Ø§ÛŒÛŒ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† ÛŒÚ© Ø¨Ø®Ø´ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†
                part_data = header.copy()
                part_data["files"] = [file_obj]
                part_data["warning"] = f"ÙØ§ÛŒÙ„ {file_obj['path']} Ø¨Ø³ÛŒØ§Ø± Ø¨Ø²Ø±Ú¯ Ø§Ø³Øª"
                parts.append(json.dumps(part_data, ensure_ascii=False, indent=2))
                continue
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ú¯Ø± Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø§ÛŒÙ† ÙØ§ÛŒÙ„ Ø§Ø² Ø­Ø¯ Ø¨Ú¯Ø°Ø±Ø¯
            if current_size + file_size + 100 > max_chars:  # 100 Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù…Ø§Ù‡Ø§ Ùˆ Ø¢Ø±Ø§ÛŒÙ‡
                # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ø®Ø´ ÙØ¹Ù„ÛŒ
                part_data = header.copy()
                part_data["files"] = current_part_files
                parts.append(json.dumps(part_data, ensure_ascii=False, indent=2))
                
                # Ø´Ø±ÙˆØ¹ Ø¨Ø®Ø´ Ø¬Ø¯ÛŒØ¯
                current_part_files = [file_obj]
                current_size = len(json.dumps(header, ensure_ascii=False)) + file_size
            else:
                current_part_files.append(file_obj)
                current_size += file_size
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¢Ø®Ø±ÛŒÙ† Ø¨Ø®Ø´
        if current_part_files:
            part_data = header.copy()
            part_data["files"] = current_part_files
            parts.append(json.dumps(part_data, ensure_ascii=False, indent=2))
        
        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªÚ¯â€ŒÙ‡Ø§ÛŒ PART
        total_parts = len(parts)
        tagged_parts = []
        for i, part in enumerate(parts, 1):
            tagged = f"---START PART {i}/{total_parts}---\n{part}\n---END PART {i}/{total_parts}---"
            tagged_parts.append(tagged)
        
        return tagged_parts
    
    def _simple_split(self, text: str, max_chars: int) -> List[str]:
        """ØªÙ‚Ø³ÛŒÙ… Ø³Ø§Ø¯Ù‡ Ù…ØªÙ†"""
        parts = []
        for i in range(0, len(text), max_chars):
            parts.append(text[i:i+max_chars])
        
        total = len(parts)
        return [f"---START PART {i+1}/{total}---\n{p}\n---END PART {i+1}/{total}---" 
                for i, p in enumerate(parts)]
    
    def deserialize_project(self, json_str: str) -> Dict[str, Any]:
        """ØªØ¨Ø¯ÛŒÙ„ JSON Ø¨Ù‡ Ø³Ø§Ø®ØªØ§Ø± Ù¾Ø±ÙˆÚ˜Ù‡"""
        try:
            # Ù¾Ø§Ú©Ø³Ø§Ø²ÛŒ ÙˆØ±ÙˆØ¯ÛŒ
            json_str = json_str.strip()
            
            # Ø­Ø°Ù markdown code blocks
            if json_str.startswith('```'):
                lines = json_str.split('\n')
                json_str = '\n'.join(lines[1:-1]) if len(lines) > 2 else json_str
            
            # Ø­Ø°Ù ØªÚ¯â€ŒÙ‡Ø§ÛŒ PART Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
            if '---START PART' in json_str:
                json_str = self._extract_from_parts(json_str)
            
            project_data = json.loads(json_str)
            
            if "files" not in project_data:
                raise ValueError("ÙØ±Ù…Øª JSON Ù†Ø§Ø¯Ø±Ø³Øª Ø§Ø³Øª. Ú©Ù„ÛŒØ¯ 'files' ÛŒØ§ÙØª Ù†Ø´Ø¯.")
            
            return project_data
            
        except json.JSONDecodeError as e:
            raise ValueError(f"Ø®Ø·Ø§ Ø¯Ø± parse Ú©Ø±Ø¯Ù† JSON: {e}")
    
    def _extract_from_parts(self, text: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ JSON Ø§Ø² Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ú†Ù†Ø¯Ú¯Ø§Ù†Ù‡"""
        import re
        
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ØªÙ…Ø§Ù… Ø¨Ø®Ø´â€ŒÙ‡Ø§
        pattern = r'---START PART \d+/\d+---\n(.*?)\n---END PART \d+/\d+---'
        matches = re.findall(pattern, text, re.DOTALL)
        
        if not matches:
            return text
        
        # ØªØ±Ú©ÛŒØ¨ Ø¨Ø®Ø´â€ŒÙ‡Ø§
        combined_files = []
        base_info = None
        
        for match in matches:
            try:
                part_data = json.loads(match)
                
                if base_info is None:
                    base_info = {
                        "project_name": part_data.get("project_name"),
                        "base_path": part_data.get("base_path"),
                        "changes_only": part_data.get("changes_only", False)
                    }
                
                if "files" in part_data:
                    combined_files.extend(part_data["files"])
                    
            except json.JSONDecodeError:
                continue
        
        result = base_info or {}
        result["files"] = combined_files
        result["total_files"] = len(combined_files)
        
        return json.dumps(result, ensure_ascii=False)
    
    def apply_changes(self, project_data: Dict[str, Any]) -> List[str]:
        """Ø§Ø¹Ù…Ø§Ù„ ØªØºÛŒÛŒØ±Ø§Øª Ø¨Ù‡ Ù¾Ø±ÙˆÚ˜Ù‡ ÙˆØ§Ù‚Ø¹ÛŒ"""
        applied_changes = []
        
        # Ø¨Ø±Ø±Ø³ÛŒ Ø­Ø§Ù„Øª changes_only
        changes_only = project_data.get("changes_only", False)
        
        if changes_only:
            # Ø­Ø§Ù„Øª ÙÙ‚Ø· ØªØºÛŒÛŒØ±Ø§Øª
            return self._apply_changes_only(project_data)
        else:
            # Ø­Ø§Ù„Øª Ú©Ù„ Ù¾Ø±ÙˆÚ˜Ù‡
            return self._apply_full_project(project_data)
    
    def _apply_changes_only(self, project_data: Dict[str, Any]) -> List[str]:
        """Ø§Ø¹Ù…Ø§Ù„ ÙÙ‚Ø· ØªØºÛŒÛŒØ±Ø§Øª"""
        applied_changes = []
        
        for file_obj in project_data.get("files", []):
            path = file_obj["path"]
            action = file_obj.get("action", "modified")
            file_path = self.project_path / path
            
            if action == "deleted":
                # Ø­Ø°Ù ÙØ§ÛŒÙ„
                if file_path.exists():
                    file_path.unlink()
                    applied_changes.append(f"â– Ø­Ø°Ù: {path}")
                    
            elif action == "added":
                # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯
                file_path.parent.mkdir(parents=True, exist_ok=True)
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(file_obj["content"])
                applied_changes.append(f"â• Ø¬Ø¯ÛŒØ¯: {path}")
                
            elif action == "modified":
                # ØªØºÛŒÛŒØ± ÙØ§ÛŒÙ„ Ù…ÙˆØ¬ÙˆØ¯
                file_path.parent.mkdir(parents=True, exist_ok=True)
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(file_obj["content"])
                applied_changes.append(f"âœï¸  ØªØºÛŒÛŒØ±: {path}")
        
        return applied_changes
    
    def _apply_full_project(self, project_data: Dict[str, Any]) -> List[str]:
        """Ø§Ø¹Ù…Ø§Ù„ Ú©Ù„ Ù¾Ø±ÙˆÚ˜Ù‡"""
        applied_changes = []
        
        # Ø¯Ø±ÛŒØ§ÙØª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯
        existing_files = set()
        for root, dirs, filenames in os.walk(self.project_path):
            root_path = Path(root)
            dirs[:] = [d for d in dirs if not self.should_ignore(root_path / d)]
            
            for filename in filenames:
                file_path = root_path / filename
                if not self.should_ignore(file_path):
                    relative_path = file_path.relative_to(self.project_path)
                    existing_files.add(str(relative_path).replace('\\', '/'))
        
        new_files = {f["path"] for f in project_data.get("files", [])}
        
        # Ø§Ø¹Ù…Ø§Ù„ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯/ØªØºÛŒÛŒØ± ÛŒØ§ÙØªÙ‡
        for file_obj in project_data.get("files", []):
            file_path = self.project_path / file_obj["path"]
            file_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(file_obj["content"])
            
            if file_obj["path"] in existing_files:
                applied_changes.append(f"âœï¸  ØªØºÛŒÛŒØ±: {file_obj['path']}")
            else:
                applied_changes.append(f"â• Ø¬Ø¯ÛŒØ¯: {file_obj['path']}")
        
        # Ø­Ø°Ù ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø­Ø°Ù Ø´Ø¯Ù‡
        deleted_files = existing_files - new_files
        for file_path_str in deleted_files:
            file_path = self.project_path / file_path_str
            if file_path.exists():
                file_path.unlink()
                applied_changes.append(f"â– Ø­Ø°Ù: {file_path_str}")
        
        return applied_changes
    
    def get_file_list(self) -> List[Tuple[str, int]]:
        """Ø¯Ø±ÛŒØ§ÙØª Ù„ÛŒØ³Øª ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø§ Ø§Ù†Ø¯Ø§Ø²Ù‡"""
        files = self.load_project_files()
        return [(f["path"], len(f["content"])) for f in files]